{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTbpuq24OXoj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.backend as K\n",
    " \n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrF6ip31GpIc",
    "outputId": "834175aa-fbda-45a0-f5a4-8668128cdad6"
   },
   "outputs": [],
   "source": [
    "image_list = os.listdir('imgs/')\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvi98Dfx0uRl"
   },
   "outputs": [],
   "source": [
    "def standarize_image(img_array,resize_pixels=256): \n",
    "  img = Image.fromarray(img_array)\n",
    " \n",
    "  cols, rows = img.size\n",
    "  extra = (rows-cols)/2\n",
    " \n",
    "  if (extra>0):  \n",
    "    crop_box = (0,extra,cols,cols+extra)\n",
    "  else:\n",
    "    crop_box = (-extra,0,rows-extra,rows) \n",
    " \n",
    "  standarized_image = img.crop(crop_box).resize((resize_pixels,resize_pixels), Image.ANTIALIAS)\n",
    " \n",
    "  standarized_image_vector = (np.asarray(standarized_image).flatten().astype(np.float32)-128)/128 \n",
    " \n",
    "  standarized_image_tensor = (np.asarray(standarized_image))\n",
    " \n",
    "  return standarized_image_tensor, standarized_image_vector, standarized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgaKZ9yazxtb",
    "outputId": "dbb1d6e5-b63e-4e2a-dea8-05a957b8b432"
   },
   "outputs": [],
   "source": [
    "x_all = []\n",
    "\n",
    "image_list = os.listdir('imgs/')\n",
    "print(image_list)\n",
    "    \n",
    "for image in image_list:\n",
    "    img_array = io.imread('imgs/' + image)\n",
    " \n",
    "    (img_tensor,_,img) = standarize_image(img_array,128)\n",
    "    x_all.append(img_tensor)\n",
    "\n",
    "# Convert the list to a 4D array \n",
    "x_all = np.array(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-rzwHg21Ap5"
   },
   "outputs": [],
   "source": [
    "#(x_train, y_train, x_test, y_test) = train_test_split(x_all, y_all, , random_state=42)\n",
    "\n",
    "#dataset = ((x_train, y_train), (x_test, y_test))\n",
    " \n",
    "np.save('MRI_preprocessed',x_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBpfRX8z8s90"
   },
   "outputs": [],
   "source": [
    "#((x_train, y_train), (x_test, y_test)) = np.load(\"/content/drive/My Drive/MRI_preprocessed.npy\",allow_pickle=True)\n",
    "\n",
    "x_train = np.load(\"MRI_preprocessed.npy\",allow_pickle=True)\n",
    "\n",
    "#X_train = np.concatenate((x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "dgvZqKjWLlRq",
    "outputId": "3c129340-79ad-4537-e018-fabcf373ba47"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(x_train[101],cmap='gray')\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
